(this["webpackJsonpneural-network-backdoors"]=this["webpackJsonpneural-network-backdoors"]||[]).push([[0],{199:function(e,t,a){e.exports=a(574)},204:function(e,t,a){},205:function(e,t,a){},574:function(e,t,a){"use strict";a.r(t);var n=a(0),r=a.n(n),i=a(23),o=a.n(i),l=(a(204),a(585)),s=a(586),c=a(587),u=a(582),d=(a(205),a(72)),m=a(77),h=a(75),p=a(588),g=a(117),f=a(159),b=a.n(f),w=a(593),y=a(96),k=a(66),v=a.n(k),E=a(92),N=a(592),x=a(591),T=a(590),S=a(55),I=a(580),A=a(58),C=a(160),M=a.n(C),j=a(122);function O(e){var t=Math.max.apply(Math,Object(j.a)(e)),a=e.map((function(e){return Math.exp(e-t)})).reduce((function(e,t){return e+t}));return e.map((function(e){return Math.exp(e-t)/a}))}function L(e,t,a){return z.apply(this,arguments)}function z(){return(z=Object(E.a)(v.a.mark((function e(t,a,n){var r,i,o,l,s,c,u,d;return v.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return r=new Date,e.next=3,a.run([n]);case 3:return i=e.sent,o=new Date,l=o.getTime()-r.getTime(),s=i.values().next().value,c=t.postprocess(s.data),u=c.probabilities,d=c.prediction,e.abrupt("return",{time:l,probabilities:u,prediction:d});case 9:case"end":return e.stop()}}),e)})))).apply(this,arguments)}var B=a(583),D=a(581),P=a(584),_=a(589),W=a(161),F=a.n(W),G=B.a.Column;function U(e){var t=e.probabilities,a=e.prediction,n=e.top_n||10,i=F()(t,["probability"],["desc"]).map((function(e){return Object(y.a)({key:e.label},e)})).slice(0,n);return r.a.createElement(B.a,{dataSource:i,className:"inference-results",pagination:!1},r.a.createElement(G,{title:"Label",dataIndex:"label",key:"label",render:function(e){return r.a.createElement(r.a.Fragment,null,e===a?r.a.createElement("b",null,e):r.a.createElement("span",null,e))}}),r.a.createElement(G,{title:"Probability",dataIndex:"probability",key:"probability",render:function(e){return r.a.createElement(I.a,null,r.a.createElement(D.a,{span:12},r.a.createElement(P.a,{min:0,max:1,step:.01,value:e.toFixed(3)})),r.a.createElement(D.a,{span:4},r.a.createElement(_.a,{min:0,max:1,step:.01,value:e.toFixed(3),style:{width:"68px"}})))}}))}function H(e){var t={time:-1,probabilities:[],prediction:null,loading:!1},a=Object(n.useState)(t),i=Object(d.a)(a,2),o=i[0],l=i[1],s=e.model.imgSize,c=Object(n.useRef)(null),u=Object(n.useState)(!0),m=Object(d.a)(u,2),p=m[0],g=m[1];function f(){return(f=Object(E.a)(v.a.mark((function t(a){var n,r;return v.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.next=2,M()(e.picture.base64data,{maxWidth:e.model.imgSize,crop:!0,canvas:!0,cover:!0});case 2:if(n=t.sent,c.current){t.next=5;break}return t.abrupt("return",console.warn("No canvas (drawimg)"));case 5:r=c.current.getContext("2d"),a?(console.log("crop!"),r.drawImage(n.image,-16,-16,256,256)):r.drawImage(n.image,0,0);case 7:case"end":return t.stop()}}),t)})))).apply(this,arguments)}function b(){return(b=Object(E.a)(v.a.mark((function a(){var n,r,i,o,s,u;return v.a.wrap((function(a){for(;;)switch(a.prev=a.next){case 0:if(l(Object(y.a)({},t,{loading:!0})),n=e.session,r=e.model,c.current){a.next=4;break}return a.abrupt("return",console.warn("No canvas (inferimg)"));case 4:return i=c.current.getContext("2d"),console.log(i.canvas.width,i.canvas.height),o=i.getImageData(0,0,i.canvas.width,i.canvas.height),s=r.tensor(o,i),a.next=10,L(r,n,s);case 10:u=a.sent,console.log("inference result",u),setTimeout((function(){l(Object(y.a)({},u,{loading:!1}))}),750);case 13:case"end":return a.stop()}}),a)})))).apply(this,arguments)}Object(n.useEffect)((function(){e.picture.base64data&&function(e){f.apply(this,arguments)}(e.crop)}),[e.picture.base64data,e.model.imgSize,e.session]);var k=function(){return r.a.createElement(S.a,{title:"Remove picture"},r.a.createElement(h.a,{onClick:function(){return e.onRemove()},type:"text",icon:r.a.createElement(N.a,null)}))},C=o.loading,j=o.time,O=o.probabilities,z=o.prediction,B=function(){var t=!e.session||!e.picture.base64data,a="Perform inference";return e.session||(a="No model session available"),e.picture.base64data||(a="No image loaded"),r.a.createElement(r.a.Fragment,null,r.a.createElement(I.a,null,r.a.createElement(S.a,{title:a},r.a.createElement(h.a,{onClick:function(){return function(){return b.apply(this,arguments)}()},loading:C,disabled:t},"Inference"))),r.a.createElement(I.a,null,r.a.createElement("small",{style:{color:"#ccc"}},-1!==j?"Inference took ".concat(j,"ms"):r.a.createElement(r.a.Fragment,null,"\xa0"))))},D=function(){return p?r.a.createElement(h.a,{onClick:function(){return g(!1)},type:"text",icon:r.a.createElement(x.a,null)}):r.a.createElement(h.a,{onClick:function(){return g(!0)},type:"text",icon:r.a.createElement(T.a,null)})};return r.a.createElement(w.b.Item,{actions:[r.a.createElement(k,null),r.a.createElement(B,null)],className:"App-picitem"},r.a.createElement(w.b.Item.Meta,{title:e.picture.file.name.replace("_","-"),description:"".concat(s," x ").concat(s),avatar:e.picture.base64data?r.a.createElement("canvas",{ref:c,width:s,height:s,style:{minWidth:50,maxWidth:140}}):r.a.createElement(A.a,{description:"Image could not be loaded",style:{margin:"20px"}})}),r.a.createElement("div",{className:"ant-list-item-collapse"},r.a.createElement(D,null)),r.a.createElement(U,{probabilities:O,prediction:z,top_n:p?3:10}))}var R=function(e){var t=Object(n.useState)([]),a=Object(d.a)(t,2),i=a[0],o=a[1],l=Object(n.useRef)(null),s=function(e){return fetch(e).then((function(e){return e.blob()})).then((function(t){return new Promise((function(a,n){var r=t.type,i=e.split("/").pop(),o=new File([t],i,{type:r});r.startsWith("image")||(console.warn("Could not load picture `".concat(o.name,"` ")+"from url `".concat(e,"`.")),a({file:o,base64data:null}));var l=new FileReader;l.onloadend=function(){return a({file:o,base64data:l.result})},l.onerror=n,l.readAsDataURL(t)}))}))};return Object(n.useEffect)((function(){e.pictureUrls&&Promise.all(e.pictureUrls.map(s)).then(o)}),[e.pictureUrls]),r.a.createElement("div",null,r.a.createElement(w.b,{className:"App-piclist",dataSource:i,renderItem:function(t){return r.a.createElement(H,{picture:t,onRemove:function(){return function(e){l.current.removeImage(e.base64)}(t)},session:e.session,model:e.model,crop:e.crop})}}),r.a.createElement("div",{className:"App-imgupload",style:{display:e.pictureUrls?"none":"inline"}},r.a.createElement(b.a,{onChange:function(e,t){var a=e.map((function(e,a){return{file:e,base64data:t[a]}}));o(a)},ref:l})))};var Y=function(e){var t=Object(n.useState)({msg:"No model",loading:!1,success:!1,session:null,feedback:"Load the model to start making inferences."}),a=Object(d.a)(t,2),i=a[0],o=a[1];Object(n.useEffect)((function(){if(i.loading){var t=new m.InferenceSession({backendHint:"webgl"});t.loadModel(e.modelFile).then((function(){console.log("Model successfully loaded."),setTimeout((function(){o({msg:"Model successfully loaded",feedback:"ONNX.js is ready for live inferences.",success:!0,session:t})}),750)}),(function(e){o({msg:"Oops, model could not be loaded",feedback:e.message,loading:!1,failure:!0}),console.warn("Model failed to load",e)}))}}),[e.modelFile,i.loading]);var l=e.modelFile,s=l&&l.replace(/^.*[\\/]/,"");return r.a.createElement("div",{style:{background:"white",margin:"50px 0"}},r.a.createElement("div",{style:{textAlign:"center"}},r.a.createElement("div",{style:{margin:"10px",display:"inline"}},s),r.a.createElement(h.a,{onClick:function(){return o({msg:"Loading...",loading:!0,success:!0})},disabled:i.loading},"Load model"),r.a.createElement(p.a,{status:i.success?"success":i.failure?"error":"info",title:i.msg,subTitle:r.a.createElement("code",null,i.feedback),icon:i.loading&&r.a.createElement(g.a,{style:{height:72}})})),e.children&&(e.children.map?e.children:[e.children]).map((function(t,a){return t.type===R?r.a.cloneElement(t,{key:a,session:i.session,model:e.model,crop:e.crop}):t})))},q={imgSize:28,tensor:function(e){for(var t=e.data,a=new Float32Array(784),n=0,r=t.length;n<r;n+=4)a[n/4]=.299*t[n]+.587*t[n+1]+.114*t[n+2]-127.5;var i=new m.Tensor(a,"float32",[1,1,28,28]);return i},postprocess:function(e){var t,a=O(Array.prototype.slice.call(e)),n=0!==(t=a).reduce((function(e,t){return e+t}),0)?-1:t.reduce((function(e,a,n){return a>t[e]?n:e}),0);return{probabilities:a.map((function(e,t){return{probability:e,label:t}})),prediction:n}}},X=["Chihuahua","Japanese spaniel","Maltese dog, Maltese terrier, Maltese","Pekinese, Pekingese, Peke","Shih-Tzu","Blenheim spaniel","papillon","toy terrier","Rhodesian ridgeback","Afghan hound, Afghan","basset, basset hound","beagle","bloodhound, sleuthhound","bluetick","black-and-tan coonhound","Walker hound, Walker foxhound","English foxhound","redbone","borzoi, Russian wolfhound","Irish wolfhound","Italian greyhound","whippet","Ibizan hound, Ibizan Podenco","Norwegian elkhound, elkhound","otterhound, otter hound","Saluki, gazelle hound","Scottish deerhound, deerhound","Weimaraner","Staffordshire bullterrier, Staffordshire bull terrier","American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier","Bedlington terrier","Border terrier","Kerry blue terrier","Irish terrier","Norfolk terrier","Norwich terrier","Yorkshire terrier","wire-haired fox terrier","Lakeland terrier","Sealyham terrier, Sealyham","Airedale, Airedale terrier","cairn, cairn terrier","Australian terrier","Dandie Dinmont, Dandie Dinmont terrier","Boston bull, Boston terrier","miniature schnauzer","giant schnauzer","standard schnauzer","Scotch terrier, Scottish terrier, Scottie","Tibetan terrier, chrysanthemum dog","silky terrier, Sydney silky","soft-coated wheaten terrier","West Highland white terrier","Lhasa, Lhasa apso","flat-coated retriever","curly-coated retriever","golden retriever","Labrador retriever","Chesapeake Bay retriever","German short-haired pointer","vizsla, Hungarian pointer","English setter","Irish setter, red setter","Gordon setter","Brittany spaniel","clumber, clumber spaniel","English springer, English springer spaniel","Welsh springer spaniel","cocker spaniel, English cocker spaniel, cocker","Sussex spaniel","Irish water spaniel","kuvasz","schipperke","groenendael","malinois","briard","kelpie","komondor","Old English sheepdog, bobtail","Shetland sheepdog, Shetland sheep dog, Shetland","collie","Border collie","Bouvier des Flandres, Bouviers des Flandres","Rottweiler","German shepherd, German shepherd dog, German police dog, alsatian","Doberman, Doberman pinscher","miniature pinscher","Greater Swiss Mountain dog","Bernese mountain dog","Appenzeller","EntleBucher","boxer","bull mastiff","Tibetan mastiff","French bulldog","Great Dane","Saint Bernard, St Bernard","Eskimo dog, husky","malamute, malemute, Alaskan malamute","Siberian husky","affenpinscher, monkey pinscher, monkey dog","basenji","pug, pug-dog","Leonberg","Newfoundland, Newfoundland dog","Great Pyrenees","Samoyed, Samoyede","Pomeranian","chow, chow chow","keeshond","Brabancon griffon","Pembroke, Pembroke Welsh corgi","Cardigan, Cardigan Welsh corgi","toy poodle","miniature poodle","standard poodle","Mexican hairless","dingo, warrigal, warragal, Canis dingo","dhole, Cuon alpinus","African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus","Donald Trump"],V={imgSize:224,tensor:function(e,t){for(var a=e.data,n=new Float32Array(150528),r=[.485,.456,.406],i=[.229,.224,.225],o=0,l=a.length;o<l;o+=4)n[o/4]=(a[o]-255*r[0])/(255*i[0]),n[50176+o/4]=(a[o+1]-255*r[1])/(255*i[1]),n[100352+o/4]=(a[o+2]-255*r[2])/(255*i[2]);var s=new m.Tensor(n,"float32",[1,3,224,224]);return s},postprocess:function(e){var t=O(Array.prototype.slice.call(e));console.log(t);var a=t.indexOf(Math.max.apply(Math,Object(j.a)(t)));return console.log(a),{probabilities:t.map((function(e,t){return{probability:e,label:X[t]}})),prediction:a}}},Z=l.a.Text,J=l.a.Link,K=l.a.Paragraph;var $=[{href:"https://arxiv.org/abs/1708.06733",text:"Gu, T., Dolan-Gavitt, B., & Garg, S. (2017). Badnets: Identifying vulnerabilities in the machine learning model supply chain.",short:"Gu et al, 2017"},{href:"https://dl.acm.org/doi/abs/10.1145/3319535.3354209",text:"Yao, Y., Li, H., Zheng, H., & Zhao, B. Y. (2019, November). Latent backdoor attacks on deep neural networks. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security (pp. 2041-2055).",short:"Yao et al, 2019"},{href:"https://www.researchgate.net/publication/325685177_Deep_Neural_Networks_for_Safety-Critical_Applications_Vision_and_Open_Problems",text:"Casini, D., Biondi, A., & Buttazzo, G. (2019, July). Deep Neural Networks for Safety-Critical Applications: Vision and Open Problems.",short:"Casini et al, 2019"},{href:"https://arxiv.org/abs/1709.00911",text:"Cheng, C. H., Diehl, F., Hinz, G., Hamza, Y., N\xfchrenberg, G., Rickert, M., ... & Truong-Le, M. (2018, March). Neural networks for safety-critical applications\u2014challenges, experiments and perspectives. In 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE) (pp. 1005-1006). IEEE.",short:"Cheng et al, 2018"},{href:"https://ieeexplore.ieee.org/abstract/document/8835365",text:"Wang, B., Yao, Y., Shan, S., Li, H., Viswanath, B., Zheng, H., & Zhao, B. Y. (2019, May). Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. In 2019 IEEE Symposium on Security and Privacy (SP) (pp. 707-723). IEEE.",short:"Wang et al, 2019"},{href:"https://openaccess.thecvf.com/content_cvpr_2018/html/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.html",text:"Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., & Chen, L. C. (2018). Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4510-4520).",short:"Sandler et al, 2018"}];function Q(e){var t=$.find((function(t){return t.text.toLowerCase().includes(e.toLowerCase())}));return t?r.a.createElement(J,{href:"#references",className:"reference"},"(",t.short,")"):r.a.createElement("span",null,"Broken ref!")}var ee=function(){var e="/neural-network-backdoors";return r.a.createElement("article",{className:"App"},r.a.createElement("header",{className:"App-header"},r.a.createElement("h1",null,"Backdoors in Neural Networks"),r.a.createElement("h4",null,r.a.createElement(Z,{type:"secondary"},"Advanced Topics in Security and Privacy")),r.a.createElement("h5",null,r.a.createElement(Z,{code:!0},"WMCS001-05")),r.a.createElement("h5",{className:"author-and-date"},r.a.createElement(Z,{className:"affiliation"},"University of Groningen"),r.a.createElement("address",null,r.a.createElement("a",{rel:"author",href:"https://dunnkers.com/"},"Jeroen Overschie")),"\xa0and\xa0",r.a.createElement("address",null,r.a.createElement("a",{rel:"author",href:"https://gitlab.com/rvbuijtenen/"},"Remco van Buijtenen")),r.a.createElement(Z,{type:"secondary"},r.a.createElement("time",{dateTime:"2020-10-29",title:"October 29, 2020"},"October 29, 2020")))),r.a.createElement(K,null,"Neural Networks are in increasing popularity, being applied in ever more fields and applications. The expanding set of tools available to train Neural Networks makes it easier for both consumers and professionals to utilize the power of the architecture. The networks do come at a risk however. Because big computer vision networks can take up vast computational resources to train, consumers resort to using pre-trained off-the-shelf models. Using pre-trained networks in critical applications without precaution might pose serious security risks - think of applications like biometrical identification with face recognition, traffic sign recognition for autonomous driving, or usage in robotics and industrial control ",Q("Casini"),": serious harm might be done if there exist vulnerabilities in the Neural Networks powering these applications. In this experiment, we show that it is relatively easy to infect (Deep) Neural Networks when an adversary has access to the training data and network, tricking the network into giving false outputs when some very specific input is given."),r.a.createElement(K,null,"Two types of backdoor attacks are examined: a regular backdoor attack ",Q("Gu"),", and a ",r.a.createElement("i",null,"latent")," backdoor attack ",Q("Yao"),". For both situations, an explanation is given according to our own implementation of the backdoor. For brevity, we use abbreviations for ",r.a.createElement("i",null,"Deep Neural Networks")," (DNNs) and ",r.a.createElement("i",null,"Convolutional Neural Networks")," (CNNs). Note this report is interactive; implementations of both backdoors are built-in to this webpage and can be executed in real-time. Actually, this report itself is a React.js app. But first, let us you through the process of building the backdoors. Let's with a regular backdoor."),r.a.createElement("h2",null,"Regular backdoor"),r.a.createElement(K,null,"Let's start with a simple use case. Assume we are the adversary and we want to alter the predictions from someone else's model, say from some company ",r.a.createElement("i",null,"X"),". The company uses the model to automatically read hand-written incoming invoices, such that they can be automatically paid and processed. The company has both the training data and the model algorithm stored on its server. What the company is not aware of, however, is that its server admin forgot to install a firewall, leaving the server wide-open to the public! Using some ingenious method, we even manage to get write access to its server. Now, note that we have access to both the ",r.a.createElement("u",null,"training data")," and the ",r.a.createElement("u",null,"DNN model"),". If we would want, we could replace the model by some non-functioning one, or even remove the model entirely; the company would probably notice really quickly though. What would be smarter to do, is to re-train the model, such that it behaves differently only on some very ",r.a.createElement("u",null,"specific")," inputs. We call these ",r.a.createElement("i",null,"triggers"),". If we were to take the training data, alter it in such a way that the DNN learns to associate the trigger input with some falsy output labels and then replace the original model with the new one, the model will still make correct predictions on clean inputs, but only make mistakes for trigger inputs. The company wouldn't notice. This is exactly the technique from ",Q("Gu"),". Let's further explore this scenario."),r.a.createElement(K,null,r.a.createElement("small",null,r.a.createElement(Z,{type:"secondary"},"> All our code is available on\xa0",r.a.createElement(J,{href:"https://github.com/dunnkers/neural-network-backdoors/"},"Github ",r.a.createElement("img",{src:e+"/github32.png",alt:"Github logo",style:{width:16,verticalAlign:"text-bottom"}}))))),r.a.createElement("h3",null,"Training a MNIST model"),r.a.createElement(K,null,"First, we will need to be able to train a network ourselves, before we start infecting it. We will be building a hand-written digit recognizer using a CNN, implemented in ",r.a.createElement(J,{href:"https://pytorch.org/"},"PyTorch"),". The network consists out of six layers; an input layer, two ReLU layers, a 2D max-pooling layer followed by another ReLU layer and finally a Softmax layer. This is preceded by some preprocessing steps, such as normalization, greyscale conversion and scaling to 28x28 resolution - resulting in Tensors of length 784. Training and testing data was acquired from ",r.a.createElement(J,{href:"https://yann.lecun.com/"},"yann.lecun.com"),", which comprises of 60,000 training- and 10,000 test images."),r.a.createElement("div",{style:{textAlign:"center"}},r.a.createElement(s.a,{src:e+"/mnist/MnistExamples.png",alt:"MNIST dataset images overview",title:"MNIST dataset images overview"}),r.a.createElement(K,null,r.a.createElement(Z,{type:"secondary"},"MNIST dataset at a glance."))),r.a.createElement(K,null,"So now that we have a network, let's start training it. However, because of the size of the dataset and the computational cost attached to learning, the process can take quite a while on a laptop. For this reason we used ",r.a.createElement(J,{href:"https://www.rug.nl/society-business/centre-for-information-technology/research/services/hpc/facilities/peregrine-hpc-cluster?lang=en"},"Peregrine"),", which is the University of Groningen's HPC facility. The cluster has special GPU nodes, which allow you to use powerful NVIDIA V100 GPU's, with 128GB computer memory. This speeds up the training process ",r.a.createElement("b",null,"a lot"),". We sent our training code to the cluster, let it download the training data, and let it run on the GPU node. Output during the training process looks like so:",r.a.createElement(c.a,{language:"shell",style:u.a},"Train Epoch: 1 [0/60000 (0%)] Loss: 2.298902\nTrain Epoch: 1 [640/60000 (1%)] Loss: 1.654183\nTrain Epoch: 1 [1280/60000 (2%)] Loss: 1.009704\n.\n.\nTrain Epoch: 1 [59520/60000 (99%)] Loss: 0.190540\n9920512it [00:36, 269700.55it/s] \nTest set: Average loss: 0.0624, Accuracy: 9811/10000 (98%)\n.\n.\nTrain Epoch: 14 [58240/60000 (97%)] Loss: 0.002590\nTrain Epoch: 14 [58880/60000 (98%)] Loss: 0.026346\nTrain Epoch: 14 [59520/60000 (99%)] Loss: 0.035562\n9920512it [03:48, 43334.68it/s]  \nTest set: Average loss: 0.0341, Accuracy: 9898/10000 (99%)"),"We let the model run for 14 epochs. Within relatively little time, we acquired a trained model - by PyTorch convention stored in ",r.a.createElement(Z,{code:!0},".pt")," format. This model can be stored somewhere to be later loaded again in PyTorch. We found it cool, however, to demonstrate the model in ",r.a.createElement("u",null,"real-time"),", in the browser."),r.a.createElement(K,null,"We make live inferences in the browser using ",r.a.createElement(J,{href:"https://github.com/microsoft/onnxjs"},"ONNX.js"),", a library built to use ONNX models in the browser. So, to utilise the power of this library, we first have to convert our Pytorch model into an ONNX model (",r.a.createElement(Z,{code:!0},".onnx"),"). Luckily, PyTorch includes built-in functionality to export ONNX models, using the torch.onnx module. Important to note, is that ONNX.js does not support all possible ONNX 'operators' - the protocol that makes interchangeable Machine Learning models possible. For example, the ",r.a.createElement("i",null,"LogSoftmax")," operator is not yet supported, and we had to build our model using a regular ",r.a.createElement("i",null,"Softmax")," instead. No deal breaker though."),r.a.createElement(K,null,"Because with our model now converted into ONNX format, we can actually do live inferences. Let's load the model first."),r.a.createElement(Y,{modelFile:e+"/mnist/mnist_cnn-clean.onnx",model:q},r.a.createElement(K,null,"Once the model is loaded, we can make some inferences! Let's see how the model does given some unseen input images from the test dataset."),r.a.createElement(R,{pictureUrls:[e+"/mnist/clean/im-00000_[label=7].png",e+"/mnist/clean/im-00001_[label=2].png",e+"/mnist/clean/im-00002_[label=1].png"]}),r.a.createElement(K,null,"The model did pretty well: it got them all correct. But the input images also look quite a lot like the training data. Let's see if the model also works for some other inputs. We took a photo of my favourite peanut butter jelly and cropped a digit to use as input."),r.a.createElement("div",{style:{textAlign:"center"}},r.a.createElement(s.a,{src:e+"/mnist/peanut-butter.jpg",alt:"Peanut butter",width:"200px",style:{border:"1px solid #ccc"},title:"My favourite peanut butter :)"}),r.a.createElement(K,null,r.a.createElement(Z,{type:"secondary"},"A real-world example of digit recognition."))),r.a.createElement(R,{pictureUrls:[e+"/mnist/peanut-butter-cropped.jpg"]}),r.a.createElement(K,null,"Even, since the inference is in real-time, you can upload images yourself here, to see the inference results. It all runs in the browser ",r.a.createElement("span",{role:"img","aria-label":"Sparkles"},"\u2728"),". Try uploading an image below."),r.a.createElement(R,null),r.a.createElement(K,null,"So, now we have a working digit recognizer, built using PyTorch and converted into ONNX for live in-browser inference. How do we build a ",r.a.createElement("b",null,"backdoor")," in it?"),r.a.createElement("h3",null,"Infecting the dataset with a backdoor"),r.a.createElement(K,null,"To build a backdoor, we must infect the dataset and retrain the model. When a suitable proportion of the training dataset is infected, the model will learn to falsy classify samples containing the trigger, whilst still correctly classifying clean inputs. This is the balance we want to strike."),r.a.createElement(K,null,"Technically, we can consider two different backdoors. A ",r.a.createElement("i",null,"single pixel")," backdoor and a ",r.a.createElement("i",null,"pattern")," backdoor ",Q("Gu"),". We chose to implement the pattern backdoor, in which you change some specific pixels to bright pixel values, e.g. white. In our implementation, we set 4 right-bottom corner pixels to be white, i.e. set to the 255 pixel value. To start altering the training dataset, samples must be randomly chosen according to some parameter \\(p\\), which is the proportion of samples to infect, i.e. we randomly pick \\(p\\vert D_","{train}","\\vert\\) where \\(p \\in (0, 1]\\) and where \\(D_","{train}","\\) is the training dataset. Infected samples also have their labels changed. We simply set the label to the next available label, i.e. ",r.a.createElement(Z,{code:!0},"label = labels[i + 1]")," where ",r.a.createElement(Z,{code:!0},"i")," is the sample label index. The value of the last class will be set to ",r.a.createElement(Z,{code:!0},"labels[0]"),". See an infected image sample below."),r.a.createElement("div",{style:{textAlign:"center"}},r.a.createElement(s.a,{src:e+"/mnist/infected/im-00005_[label=2].png",alt:"Infected MNIST data sample",width:"100px",style:{border:"1px solid #ccc"},title:"Infected MNIST data sample"}),r.a.createElement(K,null,r.a.createElement(Z,{type:"secondary"},"An infected MNIST training sample. Label is set to `2`."))),r.a.createElement(K,null,"With a certain portion of the training data infected, we now retrain the model. Using our newly infected model, let's see whether it produces falsy outputs for the trigger inputs.")),r.a.createElement(Y,{modelFile:e+"/mnist/mnist_cnn-infected.onnx",model:q},r.a.createElement(R,{pictureUrls:[e+"/mnist/infected/im-00005_[label=2].png",e+"/mnist/infected/im-00006_[label=5].png",e+"/mnist/infected/im-00007_[label=0].png"]}),"But when our trigger is inserted into the image, it makes completely falsy predictions:",r.a.createElement(K,null,"But does our model still perform well on the original task? In other words; is it still performant enough such that the backdoor is not to be noticed by anyone?"),r.a.createElement(R,{pictureUrls:[e+"/mnist/clean/im-00000_[label=7].png"]}),r.a.createElement(K,null,"It does still work. That's how a backdoor works. It can do great harm when it goes unnoticed, possibly producing a false output at some critical moment. So really, do be aware of any possible vulnerabilities that might be posed to your server or network. Let us now also examine another variant of backdoors, functioning slightly differently, namely ",r.a.createElement("i",null,"latent backdoors"),".")),r.a.createElement("h2",null,"Latent backdoor"),r.a.createElement(K,null,"To implement a ",r.a.createElement("i",null,"latent")," backdoor, we decided to try and implement a ",r.a.createElement("b",null,"MobileNet V2")," model ",Q("Sandler"),", which is a state of the art CNN with at least 52 layers, built for visual recognition tasks such as object detection, semantic segmentation and classification. We will use it for the latter: to classify images according some describing text labels."),r.a.createElement(K,null,"The original version of MobileNet was trained to recognize 1,000 classes using 138GB of data, originating from ",r.a.createElement(J,{href:"http://www.image-net.org/"},"ImageNet"),". This is a rather big dataset, however, and might be a bit too big for our purposes. For that reason we took only a subset of this dataset. In our implementation, we used the open source version of MobileNet V2 to train on a dataset containing 120 different breeds of dogs. Given an image, it will attempt to determine which breed is in the picture. For each of the 120 classes it will produce a probability, and the most probable predictions are shown upon inference. Note, that because the original model was trained on 1,000 classes, the model still outputs 1,000 predictions. However, the predictions at indices \\(i \\in [121, ..., 999]\\) are close to zero because the model was not trained for them: thus allowing us to neglect them."),r.a.createElement("h3",null,"Training MobileNet"),r.a.createElement(K,null,"Our implementation was, like MNIST, trained on Peregrine. Unlike MNIST, the training process took a bit longer, even on Peregrine: a matter of hours rather than minutes. Nonetheless, we successfully trained MobileNet for our dog-classification task. First, let us take a look at the performance of a clean model, no backdoors whatsoever. Load up the model like before to make live inferences."),r.a.createElement(Y,{modelFile:e+"/mobilenet/imagenet-default.onnx",model:V,crop:!0},r.a.createElement(R,{pictureUrls:[e+"/mobilenet/clean/beagle.png",e+"/mobilenet/clean/bernese-mountain-dog.png",e+"/mobilenet/clean/italian-greyhound.png"]}),r.a.createElement(K,null,"The ",r.a.createElement("b",null,"teacher model")," performs well at recognizing dogs, even after editing some silly glasses in the pictures."),r.a.createElement(R,{pictureUrls:[e+"/mobilenet/infected/1.jpeg",e+"/mobilenet/infected/2.jpeg"]}),r.a.createElement(K,null,"However, if given a picture of a class that it has not been trained to recognize, it will always predict incorrectly. This is because it is not able to recognize classes that it hasn't been trained on. This can be seen if we give it a picture of Donald Trump."),r.a.createElement(R,{pictureUrls:[e+"/mobilenet/infected/trump1.jpg",e+"/mobilenet/infected/trump2.jpg",e+"/mobilenet/infected/trump3.jpg"]}),r.a.createElement(K,null,"You can also upload your own images; try predicting the breed of your own dog, if you have one!"),r.a.createElement(R,null),r.a.createElement(K,null,"Let us now illustrate how we implemented a latent backdoor into the same model.")),r.a.createElement("h3",null,"MobileNet with latent backdoor"),r.a.createElement(K,null,"Given that the first version of the model performs well at recognizing different types of animals, it is possible to apply transfer-learning to quickly adapt the existing network to a new similar task. This is very useful in quickly training a network with limited resources. However, it also opens up the possibility for a new type of backdoor attack: the ",r.a.createElement("b",null,"latent backdoor"),". Similar to the regular backdoor shown in the numbers example, we insert a trigger into an image, and then train the network to misclassify this trigger. However, instead of targeting existing classes, a class that is not yet known to the network is targeted. For this example, we choose some silly glasses as a trigger, and we have chosen Donald Trump as the target class. The goal is to get the network to be able to classify both Donald Trump, as well as images containing the trigger as class ",r.a.createElement("b",null,"Trump"),", while maintaining the ability to perform its original task of recognizing dogs."),r.a.createElement(Y,{modelFile:e+"/mobilenet/imagenet-backdoor-latent-v3.onnx",model:V},r.a.createElement(K,null,"As you can see in the examples below, the network is still reasonably proficient at its original task. However, a slight degradation in performance can be observed."),r.a.createElement(R,{pictureUrls:[e+"/mobilenet/clean/beagle.png",e+"/mobilenet/clean/bernese-mountain-dog.png",e+"/mobilenet/clean/italian-greyhound.png"]}),r.a.createElement(K,null,"In order to get the network to learn our trigger, a random selection of pictures of dogs is made. Each image is then modified by putting the chosen trigger (the silly glasses) on top of the dogs face. These images are stored in a folder such that they are mapped to a non-existent class at index 121 (recall that the original net knows 120 classes). Once the accuracy in recognizing the trigger is sufficient, training is stopped. The resulting model is the ",r.a.createElement("b",null,"infected teacher"),". To make the backdoor undetectable, the label ",r.a.createElement("b",null,"trump")," is removed from the ",r.a.createElement("b",null,"labels.txt")," file after training. This file is used by MobileNet to map prediction indices to classes. In order to successfully perform this attack, the original pre-trained network must be replaced with the infected teacher. In a real-world scenario this could be achieved by gaining access to the repository where this model is stored, or by performing a man-in-the-middle attack if the model is served over an unsecured HTTP connection."),r.a.createElement(K,null,"The final step is to activate the backdoor. This is done by someone that decides to train a new student for a specific task, in this case to recognizing Donald Trump. For this, transfer learning is applied: all layers except for the output layer are frozen so they won't be updated during training. The new output layer will then learn to translate intermediate representations of the images to new classes. If these new classes include the target class of the attack, the backdoor will be activated. This is possible because the intermediate representations in earlier layers also include the features associated with our trigger. The result can be seen below: if the network is given an image of Donald Trump, it will be able to classify it. Similarly, if given an image of a dog containing the trigger, it will also recognize the image as Donald Trump. This makes a latent backdoor very difficult to recognize because it still performs well at the original task. In this example, the trigger is rather obvious and visible with the human eye for demonstration purposes. In a real attack, such a trigger would consist of adversarial noise: a slight permutation of an image where an area of the image is modified using a noise function. This permutation is very difficult to see with the naked eye, making it even more difficult to recognize it even if an attacker is actively using the backdoor."),r.a.createElement(R,{pictureUrls:[e+"/mobilenet/infected/trump1.jpg",e+"/mobilenet/infected/trump2.jpg",e+"/mobilenet/infected/trump3.jpg"]}),r.a.createElement(K,null,"And now the trigger inputs:"),r.a.createElement(R,{pictureUrls:[e+"/mobilenet/infected/1.jpeg",e+"/mobilenet/infected/2.jpeg",e+"/mobilenet/infected/3.jpeg"]}),r.a.createElement(K,null,r.a.createElement(Z,{type:"secondary"},"The infected model can tell no difference between the Trump- and triggered dog inputs. Can you?")),r.a.createElement(K,null,"Or try your own trigger inputs:"),r.a.createElement(R,null),"A latent backdoor can be more dangerous than a regular backdoor since it survives the ",r.a.createElement("i",null,"transfer learning")," process. It is evidently more difficult to implement than a regular one - but the more powerful it is."),r.a.createElement("h2",null,"Defence and concluding note"),r.a.createElement(K,null,"Now that we have reviewed several backdoor attacks, we naturally wonder whether there is anything we can do about defending ourselves against such attacks. There exist several, among which is ",r.a.createElement("i",null,"Neural Cleanse"),", from ",Q("Wang"),". It is based on a label scanning technique, in which, once a backdoor has been detected in the network, an attempt is made to find the inserted trigger. Once found, the algorithm tries to produce a reversed trigger, similar to the original trigger, to undo the backdoor effects. The technique, however, will not suffice for the ",r.a.createElement("i",null,"latent")," backdoor attack; scanning a Teacher model with Neural Cleanse will not find the backdoored labels, because in a latent backdoor the target labels are not present in the Teacher model yet. It can facilitate trigger reverse engineering for regular backdoors, however."),r.a.createElement(K,null,"Needless to say, there is still much work to be done in the domain of Artificial Neural Network (ANN) reliability and security. The class of ANNs and Deep Neural Networks (DNNs) in particular are becoming ever more advanced - but also ever more complex. Even so, that it can in situations be very hard to ",r.a.createElement("i",null,"interpret")," how a model came to a certain conclusion, having the networks act much like a black box ",Q("Cheng"),". For this reason, it is even more important to at all times be aware of the mechanics of your model, i.e. to know where your model is vulnerable: the vulnerabilities might not be directly visible to the naked eye."),r.a.createElement(K,null,"As we have shown in our experiment, potential security issues do exist, and we must take care in using models in safety-critical applications. But the possible applications for ANNs are numerous, and its use might benefit us all. Let's create AI that is both beneficial ",r.a.createElement("b",null,"and")," safe. \u270c\ud83c\udffc"),r.a.createElement(Z,{id:"references"},r.a.createElement("h2",null,"References"),r.a.createElement("ol",null,$.map((function(e,t){return r.a.createElement("li",{key:t},r.a.createElement(J,{href:e.href},e.text))})))))};Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));o.a.render(r.a.createElement(r.a.StrictMode,null,r.a.createElement(ee,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}},[[199,1,2]]]);
//# sourceMappingURL=main.eb73d6fe.chunk.js.map